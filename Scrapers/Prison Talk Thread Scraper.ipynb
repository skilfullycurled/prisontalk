{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all done\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import errno\n",
    "import traceback\n",
    "from pathlib2 import Path\n",
    "import copy\n",
    "\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import lxml.html\n",
    "import requests\n",
    "\n",
    "import smtplib\n",
    "\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "print 'all done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "firefox_win_ua = 'Mozilla/5.0 (Windows NT 6.1; rv:52.0) Gecko/20100101 Firefox/52.0'\n",
    "firefox_mac_ua = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.12; rv:58.0) Gecko/20100101 Firefox/58.0'\n",
    "safari_mac_ua = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/604.4.7 (KHTML, like Gecko) Version/11.0.2 Safari/604.4.7'\n",
    "\n",
    "domain = 'www.prisontalk.com'\n",
    "\n",
    "headers =   {\n",
    "                'Host': domain,\n",
    "                'User-Agent': firefox_win_ua,\n",
    "                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "                'Accept-Language': 'en-US,en;q=0.5',\n",
    "                'Accept-Encoding': 'gzip, deflate',\n",
    "                'DNT': '1',\n",
    "                'Connection': 'keep-alive'\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## THREAD SCRAPER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**NOTE:** *A FEW FORUMS REQUIRE BEING LOGGED IN AND THEREFORE SO WILL THE THREADS OF FORUMS, THIS SCRAPER ONLY WORKS FOR THREADS THAT DO NOT REQUIRE LOGGING IN.  THESE THREADS WILL BE ADDRESS IN ANOTHER NOTEBOOK*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### SETUP VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# GET REMAINING FORUMS BY REMOVING ALREADY RETRIEVED FORUMS FROM FULL LIST\n",
    "# remaining_forums = remove_retrieved_forums(full_forum_list, retrieved_fids)\n",
    "\n",
    "debug = True\n",
    "\n",
    "if debug:\n",
    "    root = '../examples'\n",
    "    min_time = 4\n",
    "    max_time = 7\n",
    "else:\n",
    "    root = '../data'\n",
    "    min_time = 8\n",
    "    max_time = 18\n",
    "\n",
    "in_path = root + '/threads/thread_lists/'\n",
    "out_path = root + '/threads/'\n",
    "log_path = root + '/threads/logs/'\n",
    "\n",
    "# GET FILE PATHS TO ALL CSV LISTS OF THREADS\n",
    "any_digit = re.compile(r'\\d+')\n",
    "forums = [str(path) for path in Path(in_path).iterdir() if path.is_file()]\n",
    "forum_ids = [any_digit.findall(forum_dir)[0] for forum_dir in forums]\n",
    "\n",
    "# print forum_ids\n",
    "# print forums\n",
    "# print get_next_scrape_times(min_time, max_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### SCRAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# HOW LONG WE'LL INITIALLY SCRAPE FOR BEFORE TAKING A BREAK\n",
    "start_time, scrape_time = get_next_scrape_times(min_time, max_time)\n",
    "print 'SCRAPE TIME', scrape_time\n",
    "\n",
    "for forum, forum_id in zip(forums, forum_ids):\n",
    "    \n",
    "    try:\n",
    "        logger = create_forum_logger(log_path, forum_id)\n",
    "        \n",
    "        threads = get_thread_list(forum)\n",
    "\n",
    "        for thread in threads:\n",
    "        \n",
    "            thread['thread_url'] = get_thread_url(thread['thread_id'], 0, 40)\n",
    "            thread['num_pages'] = get_num_thread_pages(thread['thread_url'], headers)\n",
    "            \n",
    "            log_thread_report('scraping', thread)\n",
    "\n",
    "            for page in range(thread['num_pages']):\n",
    "                \n",
    "                thread_page_url = get_thread_url(thread['thread_id'], page, 40)\n",
    "                thread_page = s.get(thread_page_url, headers=headers)\n",
    "                \n",
    "                if not thread_page.raise_for_status():\n",
    "                    \n",
    "                    log_thread_report('retrieved', thread, page, response=thread_page)\n",
    "                    save_html_file(thread_page, out_path, thread, page)\n",
    "                                        \n",
    "                    if time_to_take_a_break(start_time, scrape_time):\n",
    "\n",
    "                        wait_time = random.randint(20, 30) * 60\n",
    "                        send_progress_report('downtime', thread['forum_id'], wait_time)\n",
    "                        start_time, scrape_time = get_next_scrape_times(min_time, max_time, wait_time, seconds=True)\n",
    "                        print 'SCRAPE TIME', scrape_time\n",
    "                    \n",
    "                    else:\n",
    "                        wait_time = random.randint(6, 10)\n",
    "\n",
    "                    time.sleep(wait_time)\n",
    "\n",
    "            log_thread_report('completed', thread, page)\n",
    "\n",
    "        send_progress_report('forum_complete', forum_id)\n",
    "\n",
    "    except Exception as err:\n",
    "        \n",
    "        report_sent = send_critical_report(err, traceback)\n",
    "\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### GET THREAD LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_thread_list(csv_filename):\n",
    "    \"\"\"\n",
    "    Given a path to a csv file which lists all threads in a forum\n",
    "    Returns a list of dicts\n",
    "    Logs \"LOADED X THREADS FROM: path/to/csv_filename.csv\"\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_filename : str\n",
    "        The path and filename to the csv file\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    thread_list : list\n",
    "        A list of dicts where each dict is one line of the csv file\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> csv_filename = '../some/path/threads.csv'\n",
    "    >>> thread_list = get_thread_list(csv_filename)\n",
    "    >>> thread_list[0]\n",
    "    \n",
    "    {'forum_id': '65',\n",
    "     'num_thread_replies': '127',\n",
    "     'num_thread_views': '38,017',\n",
    "     'thread_id': '77500',\n",
    "     'thread_title': 'Welcome to the Juvenile Forum-Introduce yourself'}\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    thread_list = []\n",
    "    \n",
    "    with open(csv_filename) as csv_file:\n",
    "        \n",
    "        reader = csv.DictReader(csv_file)\n",
    "        \n",
    "        for thread in reader:\n",
    "                        \n",
    "            thread_list.append(thread)\n",
    "            \n",
    "    logger.info('LOADED ' + str(len(thread_list)) + ' THREADS FROM: ' + csv_filename)\n",
    "\n",
    "    return thread_list\n",
    "\n",
    "# csv_filename = '../examples/threads/thread_lists/thread_list_65.csv'\n",
    "# thread_list = get_thread_list(csv_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### GET THREAD URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_thread_url(thread_id, start_page, posts_per):\n",
    "    \n",
    "    \"\"\"\n",
    "    Given a thread id, starting page, and number of pages to show at a time, returns a URL\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    thread_id : int\n",
    "        The desired thread to retrieve\n",
    "    start_page : int\n",
    "        The page in the thread to retrieve\n",
    "    pages_per : int\n",
    "        How many pages posts to display at a time\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        A url to retrieve the page of posts of the thread requested\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> get_thread_url(671868, 0, 40)\n",
    "    'http://prisontalk.com/forums/showthread.php?t=671868&order=DESC&pp=40&page=1'\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    thread = str(thread_id)\n",
    "    order = 'DESC'\n",
    "    pp = str(posts_per) # THE MAX IS 40 FOR THREADS\n",
    "    page = str(start_page + 1) # SINCE INEVITABLE ARRAY STARTS AT THE 0th ELEMENT, ADD 1\n",
    "\n",
    "    thread_url = 'http://prisontalk.com/forums/showthread.php?'+ \\\n",
    "                                                't='+thread+ \\\n",
    "                                                '&order='+order+ \\\n",
    "                                                '&pp='+pp+ \\\n",
    "                                                '&page='+page\n",
    "    return thread_url\n",
    "\n",
    "# 'http://prisontalk.com/forums/showthread.php?t=671868&order=DESC&pp=40&page=1'\n",
    "# get_thread_url(671868, 0, 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### GET NUM THREAD PAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_num_thread_pages(thread_url, headers):\n",
    "    \"\"\"\n",
    "    Given request headers and a URL to a thread in a forum, returns the number of pages of replies in the thread\n",
    "    NOTE: Request session must already be started elsewhere\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    thread_url : str\n",
    "        The URL location of page one of threads to retreive\n",
    "    headers: dict\n",
    "        The headers to be used for requesting the page over the web\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    num_pages : int\n",
    "        The number of pages of replies in the thread\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> thread_url = 'http://prisontalk.com/forums/showthread.php?t=671868&order=DESC&pp=40&page=1'\n",
    "    >>> headers = {'Host': 'domain.com', ... 'Connection': 'keep-alive'}\n",
    "    >>> 'NO. OF PAGES:', get_num_thread_pages(thread_url, headers)\n",
    "    NO. OF PAGES: 4\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        initial_thread_page = s.get(thread_url, headers=headers)\n",
    "        \n",
    "        thread_page = str(BeautifulSoup(initial_thread_page.content, 'html.parser'))\n",
    "        no_literals = thread_page.replace('\\n', '').replace('\\t', '').replace('\\r', '')\n",
    "        thread_page = BeautifulSoup(no_literals, 'html.parser')# skip u'html PUBLIC \"-//W3C//\n",
    "    \n",
    "        # THERE IS A TOP AND BOTTOM NAV SO WE'LL JUST TAKE THE TOP\n",
    "        nav = thread_page.find_all('div', {'class':'pagenav'})[0]\n",
    "        page_x_of_y = nav.find_all('td', {'class':'vbmenu_control'})[0]\n",
    "        num_pages = page_x_of_y.text.split(' ')[-1]\n",
    "        \n",
    "    except IndexError as er:\n",
    "        \n",
    "        num_pages = 1\n",
    "    \n",
    "    return int(num_pages)\n",
    "\n",
    "# url = get_thread_url(671868, 0, 40)\n",
    "# get_num_thread_pages(url, headers) # 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### SAVE HTML FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def save_html_file(thread_page, path, thread, page):\n",
    "    \"\"\"\n",
    "    Given a http response, path, thread dict, and page number\n",
    "    Saves response.contents as dirpath/threads/fid/fid_X_tid_Y_pg_Z.html\n",
    "    Logs MM/DD/YYYY HH:MM:SS PM INFO: SAVED: dirpath/threads/fid/fid_X_tid_Y_pg_Z.html\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    thread_page : response\n",
    "        The response from a http request\n",
    "    path : str\n",
    "        The path to save the page to\n",
    "    thread: dict\n",
    "        A dict that contains at least the following keys: forum_id, thread_id\n",
    "    page : int\n",
    "        The number of the current page retrieved in the thread\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    forum_path + file_name : str\n",
    "        The path and filename of the file saved\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> save_html_file(response, 'path/to/dir/', thread, 0)\n",
    "    \"\"\"\n",
    "    \n",
    "    fid = str(thread['forum_id'])\n",
    "    tid = str(thread['thread_id'])\n",
    "    pg = str(page + 1)\n",
    "    \n",
    "    # NEW DIRECTORY PATH, EX: 'data/forums/28/'\n",
    "    forum_path = path + fid + '/'\n",
    "    # NEW FILENAME, EX: 'fid_39_pg_14.html \n",
    "    file_name = 'fid_' + fid + '_tid_' + tid + '_pg_' + pg + '.html'\n",
    "    \n",
    "    # CREATE FORUM_PATH DIRECTORY IF IT DOESN'T EXIST, ELSE, MOVE ON\n",
    "    Path(forum_path).mkdir(parents=False, exist_ok=True)\n",
    "\n",
    "    #SAVE FILE\n",
    "    with open(forum_path + file_name, 'w') as html_file:\n",
    "\n",
    "        html_file.write(thread_page.content)\n",
    "        \n",
    "    logger.info('SAVED ' + forum_path + file_name)\n",
    "\n",
    "# save_html_file(thread_page, out_path, threads[0], 0)\n",
    "# # '../examples/threads/65/fid_65_tid_77500_pg_1.hmtl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### TIME TO TAKE A BREAK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def time_to_take_a_break(start_time, minutes_to_scrape):\n",
    "    \"\"\"\n",
    "    Given the time scraping had begun, and the number of minutes for which scraping should go on for\n",
    "    Obtains the difference between the two\n",
    "    Returns True if enough time has elapsed (difference is zero)\n",
    "    Returns False if there is still time to go, (difference is greater than zero)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    start_time : datetime.datetime\n",
    "        Time the scraping began\n",
    "    minutes_to_scrape : int\n",
    "        The time in minutes the scraping should last\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    elapsed_time.total_seconds() >= seconds_to_scrape : bool\n",
    "        True if elapsed time exceeds the time in seconds that scraping was to take place for\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> five_seconds = 0.08343145\n",
    "    >>> eight_seconds = 0.1341245\n",
    "    >>> start = datetime.now()\n",
    "    >>> time.sleep(5)\n",
    "    >>> time_to_take_a_break(start, five_seconds), time_to_take_a_break(start, eight_seconds)\n",
    "    (True, False)\n",
    "    \"\"\"\n",
    "    \n",
    "    current_time = datetime.now()\n",
    "    # NOT REALLY NECCESSARY IN MINUTE CONDITIONS BUT TESTS ARE IN SECONDS AND I'M IMPATIENT\n",
    "    seconds_to_scrape = int(minutes_to_scrape * 60.0) \n",
    "    \n",
    "    elapsed_time = current_time - start_time\n",
    "    break_time = elapsed_time.total_seconds() >= seconds_to_scrape\n",
    "    # print 'BREAKTIME:', break_time, '--> SECONDS ELAPSED:', elapsed_time.total_seconds(), 'SECONDS TO SCRAPE:', seconds_to_scrape\n",
    "    \n",
    "    return break_time\n",
    "\n",
    "# five_seconds = 0.08343145 # ~5.005 seconds, returns True\n",
    "# eight_seconds = 0.1341245 # ~8.047 seconds, returns False\n",
    "# start = datetime.now()\n",
    "# time.sleep(5)\n",
    "# time_to_take_a_break(start, five_seconds), time_to_take_a_break(start, eight_seconds) # (True, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### GET NEXT SCRAPE TIMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_next_scrape_times(min_time, max_time, additional_time=0, seconds=False):\n",
    "    \"\"\"\n",
    "    Given a minimum and maximum time in minutes, returns the current time, \n",
    "    and a random length of time in minutes to scrape for.\n",
    "    Used for calculating the difference between the two function time_to_take_a_break()\n",
    "    Additionally, you can factor in some additional_time to compensate (e.g. time spent sleeping)\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    min_time : int\n",
    "        Minimum time to scrape for in minutes\n",
    "    max_time : int\n",
    "        Maximum time to scrape for in minutes\n",
    "    additional_time : int\n",
    "        Optional - An ammount of time to add in minutes if seconds is False (see below), default is zero \n",
    "    seconds : boolean\n",
    "        Optional - What time scale the additional_time is in, default is False (e.g. minutes)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    datetime.datetime\n",
    "        The current time plus any additional time\n",
    "    int\n",
    "        The time to scrape for in minutes\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> start_time, scrape_time = get_next_scrape_times(8, 18, 3)\n",
    "    >>> print 'WAIT:', wait_time, '\\n', 'NOW:', datetime.now(), '\\n', 'BEGIN NEXT SCRAPE:', start_time, '\\n', 'NEXT SCRAPE LENGTH:', scrape_time, 'minutes'\n",
    "    WAIT: 3 \n",
    "    NOW: 2018-06-20 13:36:14.822685 \n",
    "    BEGIN NEXT SCRAPE: 2018-06-20 13:39:14.821660 \n",
    "    NEXT SCRAPE LENGTH: 17 minutes\n",
    "    \"\"\"\n",
    "    \n",
    "    wait_time = additional_time * 60 if seconds == False else additional_time\n",
    "    \n",
    "    next_start_time = datetime.now() + timedelta(seconds=wait_time) # TO SUBTRACT LATER\n",
    "    next_scrape_length = random.randint(min_time, max_time) # HOW LONG WE'LL SCRAPE FOR BEFORE TAKING A BREAK\n",
    "\n",
    "    return next_start_time, next_scrape_length\n",
    "\n",
    "# wait_time = random.randint(6, 10)\n",
    "# start_time, scrape_time = get_next_scrape_times(8, 18, wait_time)\n",
    "# print 'WAIT:', int(wait_time), 'minutes' '\\n', 'NOW:', datetime.now(), '\\n', 'BEGIN NEXT SCRAPE:', start_time, '\\n', 'NEXT SCRAPE LENGTH:', scrape_time, 'minutes'\n",
    "# print ''\n",
    "# wait_time = random.randint(6, 10) * 60\n",
    "# start_time, scrape_time = get_next_scrape_times(8, 18, wait_time, seconds=True)\n",
    "# print 'WAIT:', int(wait_time / 60.0), 'minutes' '\\n', 'NOW:', datetime.now(), '\\n', 'BEGIN NEXT SCRAPE:', start_time, '\\n', 'NEXT SCRAPE LENGTH:', scrape_time, 'minutes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### REPORTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### CREATE FORUM LOGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_forum_logger(file_path, forum_id):\n",
    "    \"\"\"\n",
    "    Given a file path and thread dict \n",
    "    Returns a logger which logs to that path with the file forum_X.log in the following format\n",
    "    18/06/2018 05:27:11 PM INFO: SOME TEST MSG\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    file_path : str\n",
    "        The path to where the log should be written to\n",
    "    forum_id : int\n",
    "        The interger id of the your are going to scrape\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    logger : logger\n",
    "        The logger which saves logs to the file forum_X.log\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> logger = create_forum_logger('some/path/to/log/', thread_dict)\n",
    "    >>> logger.info('SOME TEST MSG')\n",
    "    \"\"\"\n",
    "\n",
    "    log_file = 'forum_'+ str(forum_id) + '.log'\n",
    "    msgfmt = '%(asctime)s %(levelname)s: %(message)s'\n",
    "    datefmt= '%d/%m/%Y %I:%M:%S %p'\n",
    "    \n",
    "    reload(logging)\n",
    "    logging.basicConfig(filename=file_path + log_file, level=logging.INFO, format=msgfmt, datefmt=datefmt)\n",
    "    logging.Formatter.converter = time.gmtime # CHANGE TO UTC TIME\n",
    "    logger = logging.getLogger()\n",
    "    \n",
    "    return logger \n",
    "\n",
    "# log_path = '../examples/threads/logs/'\n",
    "# fid = 0\n",
    "# logger = create_forum_logger(log_path, fid)\n",
    "# logger.info('SOME TEST MSG') # logs 18/06/2018 05:27:11 PM INFO: SOME TEST MSG to forum_0.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### LOG THREAD REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def log_thread_report(status, thread, current_page=0, response=None):\n",
    "    \"\"\"\n",
    "    Given a thread dict and a status type\n",
    "    Logs a status report to the thread log\n",
    "    18/06/2018 05:27:11 PM INFO: RETRIEVING FORUM: 65 THREAD: 77500 REPLIES: 122 PAGE: 0 OF 4\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    status: str\n",
    "        A string which indicates which message to log: 'retreiving', 'completed'\n",
    "    thread : dict\n",
    "        A dict that includes the keys: forum_id, thread_id, num_pages, num_thread_replies\n",
    "    current_page : int\n",
    "        Current page being retreived\n",
    "    *args : Added parameters for various messages\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "        None\n",
    "    \n",
    "    Examples\n",
    "    --------\n",
    "    >>> log_thread_report('scraping', thread, page)\n",
    "    \"\"\"\n",
    "    \n",
    "    fid = str(thread['forum_id'])\n",
    "    tid = str(thread['thread_id'])\n",
    "    rpls = str(thread['num_thread_replies'])\n",
    "    pg = str(current_page + 1)\n",
    "    pgs = str(thread['num_pages'])\n",
    "    \n",
    "    if response:\n",
    "        query = response.url.split('/')[-1]\n",
    "        status_code = str(response.status_code)\n",
    "\n",
    "    if status == 'scraping':\n",
    "        report = status.upper()+' FORUM: '+fid+' THREAD: '+tid+ ' REPLIES: '+rpls+' PAGES: '+pgs\n",
    "    elif status == 'retrieved':\n",
    "        report = status.upper()+' THREAD: '+tid+' PAGE: '+pg+' OF '+pgs+' FROM: '+query+' STATUS: '+status_code\n",
    "    elif status == 'completed':\n",
    "        report = status.upper()+' SCRAPING '+pg+' OF '+pgs+' PAGES FROM FORUM: '+fid+' THREAD: '+tid+ ' REPLIES: '+rpls\n",
    "        \n",
    "    logger.info(report)\n",
    "    # print report\n",
    "\n",
    "# logger = create_forum_logger(log_path, threads[0])\n",
    "# # 18/06/2018 06:25:18 PM INFO: RETREIVING FORUM: 65 THREAD: 77500 REPLIES: 127 PAGE: 3 OF 4\n",
    "# url_str = 'http://prisontalk.com/forums/showthread.php?t=671868&order=DESC&pp=40&page=1'\n",
    "# test_page = s.get(url_str, headers=headers)\n",
    "# log_thread_report('scraping', threads[0])\n",
    "# log_thread_report('retrieved', threads[0], 0, response=test_page)\n",
    "# log_thread_report('completed', threads[0], 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### SEND PROGRESS REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def send_progress_report(progress, forum_id, seconds=0, total_forums=0, text=False):\n",
    "    \n",
    "    try:\n",
    "\n",
    "        if progress == 'forum_complete':\n",
    "\n",
    "            headline = 'FINISHED SCRAPING LIST OF THREADS FROM FORUM ' + str(forum_id) #+ '\\r\\n'\n",
    "            other_info = '' # MAYBE ADD HOW MANY FORUMS ARE LEFT?\n",
    "            closing = '\\r\\n' + 'TALK SOON!'\n",
    "\n",
    "        elif progress =='downtime':\n",
    "\n",
    "            headline = 'TAKING A BREAK FOR ' + str(int(seconds/60.0)) + ' MINUTES TO KEEP UNDER THE RADAR' #+ '\\r\\n'\n",
    "            other_info = '\\r\\n'+ 'STILL DOWNLOADING THREADS FROM FORUM ' + str(forum_id) #+ '\\r\\n'\n",
    "            closing = '\\r\\n' + 'BE SEEING YOU...!'\n",
    "\n",
    "        elif progress == 'finished':\n",
    "\n",
    "            headline = 'IT IS FINISHED: ALL ' + str(total_forums) + ' LISTS OF THREADS DOWNLOADED' #+ '\\r\\n'\n",
    "            other_info = '\\r\\n' + 'LAST FORUM DOWNLOADED: ' + str(forum_id) #+ '\\r\\n'\n",
    "            closing = '\\r\\n' +'I\\'M PRETTY CACHED, AND GRATEFUL WE DIDN\\'T GET BANNED. PEACE.'\n",
    "\n",
    "        else:\n",
    "\n",
    "            headline = 'AN UNKNOWN PROGRESS STATUS WAS PASSED: ' + progress #+ '\\r\\n'\n",
    "            other_info = '\\r\\n' + 'CONTINUING TO DOWNLOAD THREADS FROM FORUM: ' + str(forum_id) #+ '\\r\\n'\n",
    "            closing = '\\r\\n' + 'SORRY.'\n",
    "\n",
    "        logger.info(headline)\n",
    "\n",
    "        email_msg = MIMEMultipart()\n",
    "\n",
    "        email_msg['From']=' YOUR SCRAPER'\n",
    "        email_msg['To'] = 'YOUR EMAIL ADDRESS'\n",
    "        email_msg['Subject'] = 'PRISONTALK: PROGRESS REPORT'\n",
    "        email_msg.attach(MIMEText(headline + other_info + closing, 'plain'))\n",
    "\n",
    "        smtp_gmail = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        smtp_gmail.starttls()\n",
    "        smtp_gmail.login('YOUR GMAIL EMAIL ADDRESS', 'YOUR GMAIL EMAIL PASSWORD')\n",
    "\n",
    "        smtp_gmail.sendmail(email_msg['From'], email_msg['To'], email_msg.as_string())\n",
    "\n",
    "        if text:\n",
    "\n",
    "            text_msg = MIMEMultipart()\n",
    "\n",
    "            text_msg['From']= 'YOUR SCRAPER'\n",
    "            text_msg['To'] = 'YOUR PHONE NUMBER'\n",
    "            text_msg['Subject'] = 'GOOD NEWS EVERYONE!'\n",
    "            text_msg.attach(MIMEText(progress.upper()))\n",
    "\n",
    "            smtp_gmail.sendmail(text_msg['From'], text_msg['To'], text_msg.as_string())\n",
    "\n",
    "        logger.info('PROGRESS REPORT SENT VIA ' + ('TEXT & EMAIL' if text == True else 'EMAIL') + '!')\n",
    "\n",
    "        smtp_gmail.close()\n",
    "        \n",
    "    except Exception as err:\n",
    "        \n",
    "        err_type = err.__class__.__name__\n",
    "        \n",
    "        logger.info('COULDN\\'T SEND PROGRESS REPORT:', err_type, err) \n",
    "        logger.info('TRIED TO REACH YOU. GOT VOICEMAIL. I THINK I\\'LL JUST QUIT WHILE I\\'M AHEAD')\n",
    "        \n",
    "        return False \n",
    "\n",
    "\n",
    "# forum_id = 65\n",
    "# seconds = 600\n",
    "# list_of_forums = [65, 105, 122, 320]\n",
    "\n",
    "# send_progress_report('downtime', forum_id, seconds)\n",
    "# send_progress_report('forum_complete', forum_id, text=True)\n",
    "# send_progress_report('finished', forum_id, total_forums=len(list_of_forums), text=True)\n",
    "# send_progress_report('continuing', forum_id, text=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### SEND CRITICAL FAILURE REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "code_folding": [],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def send_critical_report(err, tb):\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        logger.info('CRITICAL ERROR: ' + err.__class__.__name__ + ' ' + str(err))\n",
    "\n",
    "        text_msg = MIMEMultipart()\n",
    "\n",
    "        text_msg['From']=' YOUR SCRAPER'\n",
    "        text_msg['To'] = 'YOUR PHONE NUMBER'\n",
    "        text_msg['Subject'] = ' DON\\'T PANIC BUT...'\n",
    "        text_body = 'CHECK YOUR EMAIL.'\n",
    "\n",
    "        text_msg.attach(MIMEText(text_body))\n",
    "\n",
    "        \n",
    "        email_msg = MIMEMultipart()\n",
    "\n",
    "        email_msg['From']=' YOUR SCRAPER'\n",
    "        email_msg['To'] = 'YOUR EMAIL ADDRESS'\n",
    "        email_msg['Subject'] = 'PRISONTALK: CRITICAL ERROR REPORT'\n",
    "        \n",
    "        tb_str = tb.format_exc() # REMOVE IN THE FUTURE AND ADD DIRECTLY TO BODY OR KEEP FOR CLARITY?\n",
    "        email_body = 'ERROR:\\r\\n' + \\\n",
    "                    '\\r\\n' + \\\n",
    "                    tb_str + \\\n",
    "                    '\\r\\n' + \\\n",
    "                    'TRIED TO REACH YOU.\\r\\n' + \\\n",
    "                    'GOT VOICEMAIL.\\r\\n' + \\\n",
    "                    'GET READY FOR THE THUNDERDOME.\\r\\n' + \\\n",
    "                    'SHUT IT DOWN FOLKS. SHUT IT DOWN.'\n",
    "\n",
    "        email_msg.attach(MIMEText(email_body, 'plain'))\n",
    "\n",
    "\n",
    "        smtp_gmail = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "        smtp_gmail.starttls()\n",
    "        smtp_gmail.login('YOUR GMAIL EMAIL ADDRESS', 'YOUR GMAIL EMAIL PASSWORD')\n",
    "\n",
    "        smtp_gmail.sendmail(text_msg['From'], text_msg['To'], text_msg.as_string())\n",
    "        smtp_gmail.sendmail(email_msg['From'], email_msg['To'], email_msg.as_string())\n",
    "        \n",
    "        smtp_gmail.close()\n",
    "        logger.info('CRITICAL ERROR: REPORT SENT VIA TEXT & EMAIL')\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as err:\n",
    "                \n",
    "        logger.info('DOUBLE CRITICAL ERROR: ' + err.__class__.__name__ + ' ' + str(err)) \n",
    "        logger.info('TRIED TO REACH YOU. GOT VOICEMAIL. SHUT IT DOWN FOLKS! SHUT IT DOWN.')\n",
    "        \n",
    "        return False \n",
    "\n",
    "# # TEST IN A LOOP TO MAKE SURE IT WILL EXIT AND YOU WON'T BE SPAMMED BY YOUR OWN PROGRAM\n",
    "# for i in range(2):\n",
    "    \n",
    "#     try:\n",
    "#         1/0\n",
    "#     except Exception as err:\n",
    "\n",
    "#         report_sent = send_critical_report(err, traceback)\n",
    "#         print 'REPORT SENT:', report_sent\n",
    "\n",
    "#         raise        \n",
    "\n",
    "# # SHOULD PRINT THE FOLLOWING AND SEND *ONE* TEXT AND EMAIL OF MESSAGE ABOVE\n",
    "# # REPORT SENT: True\n",
    "# # ---------------------------------------------------------------------------\n",
    "# # ZeroDivisionError                         Traceback (most recent call last)\n",
    "# # ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### HELPERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### GET RETRIEVAL TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_retrieval_time(replies, replies_per_page):\n",
    "    \"\"\"\n",
    "    Given a number of threads and the threads per page\n",
    "    Returns an the time in minutes of how long it will take to download all of the pages\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    replies : str\n",
    "        The number of threads\n",
    "    replies_per_page : int\n",
    "        The number of threads on each page\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    total_minutes : int\n",
    "        The total number of minutes it will take to download the pages of replies\n",
    "        \n",
    "    Examples\n",
    "    --------\n",
    "    >>> get_retrieval_time(4440, 40)\n",
    "    12\n",
    "    \"\"\"\n",
    "    \n",
    "    average_page_wait = 7\n",
    "    \n",
    "    pages = int(replies)/replies_per_page\n",
    "    \n",
    "    total_seconds = pages * 7\n",
    "    \n",
    "    total_minutes = total_seconds/60\n",
    "    \n",
    "    return total_minutes\n",
    "\n",
    "# get_retrieval_time(4440, 40) # 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### PRINT HEADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def print_headers(response):\n",
    "    \n",
    "    print 'RESPONSE HEADERS'\n",
    "    for key, val in response.headers.iteritems():\n",
    "        print key + ':', val\n",
    "    print ''\n",
    "    print 'REQUEST HEADERS'\n",
    "    for key, val in response.request.headers.iteritems():\n",
    "        print key + ':', val\n",
    "        \n",
    "# s = requests.session()\n",
    "# test_response = s.get('http://prisontalk.com', headers=headers)\n",
    "# print_headers(test_response)\n",
    "\n",
    "# # RESPONSE HEADERS\n",
    "# # Date: Mon, 26 Feb 2018 20:57:24 GMT\n",
    "# # Server: Apache/2.2.3 (CentOS)\n",
    "# # ...\n",
    "# # Transfer-Encoding: chunked\n",
    "# # Content-Type: text/html; charset=ISO-8859-1\n",
    "    \n",
    "# # REQUEST HEADERS\n",
    "# # Connection: keep-alive\n",
    "# # Accept-Encoding: gzip, deflate\n",
    "# # ...\n",
    "# # DNT: 1\n",
    "# # Host: www.prisontalk.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### EXCEPTIONS TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# for i in [0,1,2]:\n",
    "    \n",
    "#     try:\n",
    "#         if i == 1:\n",
    "#             1/0\n",
    "#         else: \n",
    "#             print 'i is equal to', i\n",
    "        \n",
    "#     except Exception as err:\n",
    "\n",
    "# #         print err.__class__.__name__, err\n",
    "        \n",
    "# #         print traceback.format_exc()\n",
    "\n",
    "#         raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "365px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_position": {
    "height": "535px",
    "left": "0px",
    "right": "1073px",
    "top": "107px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
