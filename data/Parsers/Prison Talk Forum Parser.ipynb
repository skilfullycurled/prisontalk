{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## NOTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### RESOURCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# https://brennan.io/2016/03/02/logging-in-with-requests/\n",
    "# https://kazuar.github.io/scraping-tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'all done'\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime\n",
    "import collections\n",
    "import re\n",
    "import copy\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "from bs4 import BeautifulSoup, NavigableString, Tag\n",
    "import lxml.html\n",
    "import requests\n",
    "from string import capwords\n",
    "from titlecase import titlecase\n",
    "from pathlib2 import Path\n",
    "import unicodecsv as csv\n",
    "\n",
    "pprint('all done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### FOR INDIVIDUAL TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "forum = str(65)\n",
    "page = str(1)\n",
    "file_name = 'fid_'+forum+'_pg_'+page+'.html'\n",
    "file_path = '../data/forums/'+forum+'/'+file_name\n",
    "\n",
    "html_page = open(str(file_path), 'r').read()\n",
    "thread_page = BeautifulSoup(html_page, 'html.parser')\n",
    "thread_page = str(thread_page)\n",
    "no_literals = thread_page.replace('\\n', '').replace('\\t', '').replace('\\r', '')\n",
    "thread_page = BeautifulSoup(no_literals, 'html.parser') #s kip u'html PUBLIC \"-//W3C//\n",
    "\n",
    "threads = get_threads(thread_page)\n",
    "# cleaned_threads = clean_threads(threads)\n",
    "# data = get_thread_data(cleaned_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### LOAD HTML LIST OF THREADS AND EXTRACT DATA TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "\n",
    "if debug:\n",
    "    in_path = '../examples/forums/'\n",
    "    out_path = '../examples/threads/'\n",
    "else:\n",
    "    in_path = '../data/forums/'\n",
    "    out_path = '../data/threads/'\n",
    "\n",
    "forum_paths = [path for path in Path(in_path).iterdir() if (path.is_dir() and path.name != 'logs' and path.name != 'restricted')]\n",
    "\n",
    "for forum_path in forum_paths:\n",
    "\n",
    "    forum_id = forum_path.name\n",
    "    \n",
    "    num_threads = 0\n",
    "    \n",
    "    with open(out_path + 'thread_list_' + forum_id + '.csv', 'a') as csv_file:\n",
    "\n",
    "        fieldnames = ['forum_id', 'thread_id', 'thread_title', 'num_thread_replies', 'num_thread_views']\n",
    "\n",
    "        writer = csv.writer(csv_file, delimiter=',')\n",
    "        writer.writerow(fieldnames)\n",
    "        \n",
    "        file_paths = [path for path in forum_path.iterdir() if path.is_file()]\n",
    "\n",
    "        for file_path in file_paths:\n",
    "\n",
    "            # LOAD WEBPAGE AND REMOVE STRING LITERALS\n",
    "            html_page = open(str(file_path), 'r').read()\n",
    "            thread_page = BeautifulSoup(html_page, 'html.parser')\n",
    "            thread_page = str(thread_page)\n",
    "            no_literals = thread_page.replace('\\n', '').replace('\\t', '').replace('\\r', '')\n",
    "            thread_page = BeautifulSoup(no_literals, 'html.parser') #s kip u'html PUBLIC \"-//W3C//\n",
    "            \n",
    "            # EXTRACT RELEVANT DATA\n",
    "            threads = get_threads(thread_page)\n",
    "            cleaned_threads = clean_threads(threads)\n",
    "            data = get_thread_data(cleaned_threads)\n",
    "            \n",
    "            num_threads += len(data)\n",
    "\n",
    "            for thread in data:\n",
    "                row = [forum_id] + thread\n",
    "                writer.writerow(row)\n",
    "                \n",
    "    print 'FINISHED PROCESSING', num_threads, 'THREADS FROM FORUM', forum_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### EXTRACT NAV FOR NUMBER OF PAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# NOTE: THIS DOES NOT ASSUME EVERY THREAD PAGE WILL HAVE >100 THREADS\n",
    "\n",
    "def get_num_thread_pages(el):\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        # THERE IS A TOP AND BOTTOM NAV SO WE'LL JUST TAKE THE TOP\n",
    "        nav = el.find_all('div', {'class':'pagenav'})[0]\n",
    "        page_x_of_y = nav.find_all('td', {'class':'vbmenu_control'})[0]\n",
    "        num_pages = page_x_of_y.text.split(' ')[-1]\n",
    "        \n",
    "    except IndexError as er:\n",
    "        \n",
    "        num_pages = 1\n",
    "    \n",
    "    return num_pages\n",
    "\n",
    "get_num_thread_pages(thread_page)  #263"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### EXTRACT ALL THREADS, THEN REMOVE 'DIVIDER'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_threads(el):\n",
    "    \n",
    "    thread = copy.copy(el)\n",
    "    \n",
    "    posts = thread.find_all(id=re.compile('threadbits_forum'))\n",
    "    \n",
    "    divider = posts[0].find_all('td', {'class' : 'thead'})\n",
    "    \n",
    "    if divider:\n",
    "        \n",
    "        divider[0].parent.decompose()\n",
    "    \n",
    "    # NEED TO REMOVE DIVIDER BETWEEN STICKY POSTS AND REGULAR\n",
    "#     posts[0].find_all('td', {'class' : 'thead'})[0].parent.decompose()\n",
    "    \n",
    "    return posts[0]\n",
    "\n",
    "threads = get_threads(thread_page)\n",
    "len(threads) # 103 (since it's the first page, it's 100 + 3 sticky's at the top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### REMOVE HTML TABLE COLUMNS 0, 1, AND 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def clean_threads(threads):\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    idx = 0\n",
    "\n",
    "    for thread in threads:\n",
    "        \n",
    "        cols = thread.find_all('td')\n",
    "        \n",
    "        cols = [cols[2], cols[4], cols[5]]\n",
    "            \n",
    "        data.append(cols)\n",
    "\n",
    "        idx += 1\n",
    "    \n",
    "    return data\n",
    "\n",
    "cleaned_threads = clean_threads(threads)\n",
    "len(cleaned_threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### DETECT IF THREAD WAS MOVED, EXTRACT ID, TITLE, REPLIES, AND VIEWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_thread_data(cleaned):\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for el in cleaned:\n",
    "        \n",
    "        thread_id = get_thread_id(el)\n",
    "        thread_title = get_thread_title(el)\n",
    "        \n",
    "        try:\n",
    "            \n",
    "            if is_moved_thread(el):\n",
    "                \n",
    "                num_thread_replies = 'moved'\n",
    "                num_thread_views = 'moved'\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                num_thread_replies = get_thread_replies(el)\n",
    "                num_thread_views = get_thread_views(el)\n",
    "\n",
    "            row = [thread_id, thread_title, num_thread_replies, num_thread_views]\n",
    "\n",
    "            rows.append(row)\n",
    "    \n",
    "        except Exception as e:\n",
    "            \n",
    "            print e, '-', thread_id + ':', thread_title\n",
    "        \n",
    "    return rows\n",
    "\n",
    "# thread = '../data/forums/645/fid_645_pg_26.hmtl'\n",
    "# [[u'541001', u'Me n my MWI are celebrating 1year together!!!', u'12', u'676'],\n",
    "#  [u'540962', u'Question about federal visit form HELP!!!', 'moved', 'moved']]\n",
    "threads = get_thread_data(cleaned_threads)\n",
    "print(len(threads))\n",
    "# threads[72:74]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### GET THREAD ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'77500'"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: CHANGED B/C ORIGINAL METHOD PICKED UP AN HREF FOR WHICH THE LINK WAS A #\n",
    "\n",
    "def get_thread_id(el):\n",
    "\n",
    "    href = el[0].find_all('a', id=re.compile('thread_title'))[0]['href']\n",
    "    return href.split('=')[-1]\n",
    "\n",
    "get_thread_id(cleaned_threads[0])# u'77500'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### GET THREAD TITLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_thread_title(el):\n",
    "    \n",
    "    text = el[0].find_all(id=re.compile('thread_title'))[0].text\n",
    "    # <a href=\"show... id=\"thread_title_708682\"...\">LASO Chit Chat 2018</a>\n",
    "    return text\n",
    "\n",
    "get_thread_title(cleaned_threads[-1]) # u'Some tips on prison \"etiquette\".'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### DETECT IF THREAD HAS BEEN MOVED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def is_moved_thread(el):\n",
    "    \n",
    "    moved = el[0].find_all(string=re.compile('Moved'))\n",
    "    # <a href=\"show... id=\"thread_title_708682\"...\">LASO Chit Chat 2018</a>\n",
    "    return bool(moved)\n",
    "\n",
    "# thread = '../data/forums/645/fid_645_pg_26.hmtl'\n",
    "is_moved_thread(cleaned_threads[73]) # True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### GET NO. OF REPLIES TO THREAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_thread_replies(el):\n",
    "    # <td align='...'><a href=\"...\" onclick=\"...\">540</a></td>\n",
    "    return el[1].a.text\n",
    "\n",
    "# get_thread_replies(cleaned_threads[0]) # u'540'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### GET NO. OF TIMES THREAD HAS BEEN VIEWED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_thread_views(el):\n",
    "    # <td align=\"center\" class=\"alt2\">92,824</td>\n",
    "    return el[2].text\n",
    "\n",
    "# get_thread_views(cleaned_threads[0]) # u'92,824'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### TO DOUBLE CHECK FOR A PREVIOUS ERROR IN WHICH SOME THREAD IDS WERE '#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "for thread_path in thread_paths:\n",
    "    \n",
    "    threads = pd.read_csv(thread_path)\n",
    "    \n",
    "    fid = threads.at[0, 'forum_id']\n",
    "    contains_hash = '#' in threads['thread_id'].values\n",
    "    \n",
    "    print str(fid) + ':', contains_hash\n",
    "\n",
    "# 92: False\n",
    "# 38: False\n",
    "# 39: False\n",
    "# 72: False\n",
    "# 1506: False\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "194px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
